{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis for Context-Aware ALD Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contrains the error and qualitative analysis for different models trained on CAD for Abusive Language Detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "import seaborn as sns\n",
    "import os \n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read output test file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../../modernbert-class_cad_eval_test_outputs.jsonl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the jsonl file and read it line by line\n",
    "def get_error_stats(file_path):\n",
    "    true_predictions, tp, tn, false_predictions, fp, fn = 0, 0, 0, 0, 0, 0\n",
    "    model_pred_1, model_pred_0 = 0, 0\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            # Parse the JSON object from each line\n",
    "            json_obj = json.loads(line.strip())\n",
    "            if int(json_obj['pred_label']) == int(json_obj['y']):\n",
    "                true_predictions += 1\n",
    "                if int(json_obj['pred_label']) == 1:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "            else:\n",
    "                false_predictions += 1\n",
    "                if int(json_obj['pred_label']) == 1:\n",
    "                    fp += 1\n",
    "                else:\n",
    "                    fn += 1\n",
    "            \n",
    "            if int(json_obj['pred_label']) == 1:\n",
    "                model_pred_1 += 1\n",
    "            else:\n",
    "                model_pred_0 += 1\n",
    "\n",
    "    return {\n",
    "        \"true_predictions\": true_predictions,\n",
    "        \"true_positives\": tp,\n",
    "        \"true_negatives\": tn,\n",
    "        \"false_predictions\": false_predictions,\n",
    "        \"false_positives\": fp,\n",
    "        \"false_negatives\": fn,\n",
    "        \"model_pred_1\": model_pred_1,\n",
    "        \"model_pred_0\": model_pred_0\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  bert-class\n",
      "Model:  modernbert-class\n",
      "Model:  bert-concat\n",
      "Model:  bertwithneighconcat\n",
      "Model:  gat-test\n",
      "Stats written to model_error_stats.csv\n"
     ]
    }
   ],
   "source": [
    "models = [\"bert-class\", \"modernbert-class\", \"bert-concat\", \"bertwithneighconcat\", \"gat-test\"]\n",
    "stats_list = []\n",
    "\n",
    "for model in models:\n",
    "    file_path = os.path.join(\"../..\", model + \"_cad_eval_test_outputs.jsonl\")\n",
    "    print(\"Model: \", model)\n",
    "    stats = get_error_stats(file_path)\n",
    "    stats[\"model\"] = model  # Add model name to the stats\n",
    "    stats_list.append(stats)\n",
    "\n",
    "# Write stats to a CSV file\n",
    "output_file = \"model_error_stats.csv\"\n",
    "with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=[\n",
    "        \"model\", \"true_predictions\", \"true_positives\", \"true_negatives\",\n",
    "        \"false_predictions\", \"false_positives\", \"false_negatives\",\n",
    "        \"model_pred_1\", \"model_pred_0\"\n",
    "    ])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(stats_list)\n",
    "\n",
    "print(f\"Stats written to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the correspondance between comment/post ids and graph files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/celianouri/anaconda3/envs/hatedisc/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# output content of 100 first graph objetcs into the sample-reanno folder in data folder\n",
    "graph_input_dir = \"../../data/processed_graphs/processed/\"\n",
    "index_file = \"../../data/cad-test-idx-many.txt\"\n",
    "output_file = \"eval_set_output.csv\"\n",
    "output_dic = {}\n",
    "\n",
    "def extract_info_from_graph(index_file, output_file):\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "        fieldnames = ['filename', 'id', 'reddit_url', 'label', 'anno_ctx', 'anno_tgt', 'anno_tgt_cat', 'body', 'index_in_conv', 'conv_len']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        with open(index_file, \"r\") as file:\n",
    "            indices = file.readlines()\n",
    "            indices = [int(index.strip()) for index in indices]\n",
    "            for index in indices:\n",
    "                input_file = f\"{graph_input_dir}graph-{index}.pt\"\n",
    "                try:\n",
    "                    # Load the.pt file\n",
    "                    graph = torch.load(input_file)\n",
    "                    true_index = [i for i in range(len(graph.y_mask)) if graph.y_mask[i] == True]\n",
    "                    assert len(true_index) == 1\n",
    "                    true_index = true_index[0]\n",
    "\n",
    "                    comment = graph.x_text[true_index]\n",
    "                    x, a2, a3, label = comment\n",
    "                    my_id = x.get('id', '')\n",
    "                    permalink = x.get('permalink', '')\n",
    "                    reddit_url = 'https://www.reddit.com' + permalink\n",
    "                    \n",
    "                    label = x.get('label', '')\n",
    "                    anno_ctx = x.get('anno_ctx', '')\n",
    "                    anno_tgt = x.get('anno_tgt', '')\n",
    "                    anno_tgt_cat = x.get('anno_tgt_cat', '')\n",
    "                    body = x.get('body', '')\n",
    "                    \n",
    "                    # Write to CSV\n",
    "                    writer.writerow({\n",
    "                        'filename': input_file,\n",
    "                        'id': my_id,\n",
    "                        'reddit_url': reddit_url,\n",
    "                        'label': label,\n",
    "                        'anno_ctx': anno_ctx,\n",
    "                        'anno_tgt': anno_tgt,\n",
    "                        'anno_tgt_cat': anno_tgt_cat,\n",
    "                        'body': body,\n",
    "                        'index_in_conv': true_index,\n",
    "                        'conv_len': len(graph.y_mask)\n",
    "                    })\n",
    "\n",
    "                    #target_comment = graph.x_text[true_index]\n",
    "                    #print(target_comment)\n",
    "\n",
    "\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"File {input_file} not found.\")\n",
    "\n",
    "\n",
    "extract_info_from_graph(index_file, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check model errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bot-gat-dir-3l-cad-512-7_3625338_eval_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete! Data saved to ../bertclass-cad-512-123_3625347_eval_outputs.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# Input JSONL file\n",
    "input_file = \"../bertclass-cad-512-123_3625347_eval_outputs.jsonl\"\n",
    "# Output CSV file\n",
    "output_file = \"../bertclass-cad-512-123_3625347_eval_outputs.csv\"\n",
    "\n",
    "# Read the JSONL file and extract the data\n",
    "data = []\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line.strip())\n",
    "        obj['tp'], obj['tn'], obj['fp'], obj['fn'] = 0, 0, 0, 0\n",
    "        if int(obj['pred_label']) == int(obj['y']):\n",
    "            if int(obj['pred_label']) == 1:\n",
    "                obj['tp'] = 1\n",
    "            else:\n",
    "                obj['tn'] = 1\n",
    "        else:\n",
    "            if int(obj['pred_label']) == 1:\n",
    "                obj['fp'] = 1\n",
    "            else:\n",
    "                obj['fn'] = 1\n",
    "        data.append(obj)\n",
    "\n",
    "# Flatten and normalize arrays or complex fields into strings\n",
    "def flatten_value(value):\n",
    "    if isinstance(value, list):\n",
    "        return \";\".join(map(str, value))  # Join list elements with semicolons\n",
    "    return value\n",
    "\n",
    "# Get all unique keys in the JSON objects (assuming consistent fields)\n",
    "if data:\n",
    "    headers = data[0].keys()\n",
    "else:\n",
    "    raise ValueError(\"The JSONL file is empty or malformed.\")\n",
    "\n",
    "# Write to CSV\n",
    "with open(output_file, 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    for item in data:\n",
    "        flattened_item = {key: flatten_value(value) for key, value in item.items()}\n",
    "        writer.writerow(flattened_item)\n",
    "\n",
    "print(f\"Conversion complete! Data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "bert_results = pd.read_csv(\"../bertclass-cad-512-123_3625347_eval_outputs.csv\")\n",
    "gat3l_results = pd.read_csv(\"../bot-gat-dir-3l-cad-512-7_3625338_eval_outputs.csv\")\n",
    "gat2l_results = pd.read_csv(\"../bot-gat-dir-2l-cad-512-7_3624560_eval_outputs.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reddit_url</th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>anno_ctx</th>\n",
       "      <th>anno_tgt</th>\n",
       "      <th>anno_tgt_cat</th>\n",
       "      <th>label</th>\n",
       "      <th>y</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>x</th>\n",
       "      <th>masked_index</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>el5eh5l</td>\n",
       "      <td>https://www.reddit.com/r/TumblrInAction/commen...</td>\n",
       "      <td>4</td>\n",
       "      <td>Seriously though, what the hell am I supposed ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.4662129580974579, 0.13268911838531494]</td>\n",
       "      <td>{'id': 'el5eh5l', 'name': 't1_el5eh5l', 'autho...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>etotgus</td>\n",
       "      <td>https://www.reddit.com/r/TumblrInAction/commen...</td>\n",
       "      <td>36</td>\n",
       "      <td>I agree. Like, I just deal with it because I d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.24242620170116425, 0.11224387586116791]</td>\n",
       "      <td>{'id': 'etotgus', 'name': 't1_etotgus', 'autho...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ep0yt9p</td>\n",
       "      <td>https://www.reddit.com/r/TumblrInAction/commen...</td>\n",
       "      <td>39</td>\n",
       "      <td>Udon 4 life</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.141236662864685, -0.6677318215370178]</td>\n",
       "      <td>{'id': 'ep0yt9p', 'name': 't1_ep0yt9p', 'autho...</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>etnmw0w</td>\n",
       "      <td>https://www.reddit.com/r/TumblrInAction/commen...</td>\n",
       "      <td>46</td>\n",
       "      <td>Feminist, Feminism, *Funny, LOL*</td>\n",
       "      <td>PreviousContent</td>\n",
       "      <td>feminists</td>\n",
       "      <td>political affiliation</td>\n",
       "      <td>AffiliationDirectedAbuse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-1.1837022304534912, 0.9363416433334351]</td>\n",
       "      <td>{'id': 'etnmw0w', 'name': 't1_etnmw0w', 'autho...</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emzvb9e</td>\n",
       "      <td>https://www.reddit.com/r/CCJ2/comments/bmuhp3/...</td>\n",
       "      <td>2</td>\n",
       "      <td>Also can't take a shit in a public bathroom wi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-1.0287977457046509, 0.5232383608818054]</td>\n",
       "      <td>{'id': 'emzvb9e', 'name': 't1_emzvb9e', 'autho...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                         reddit_url  index  \\\n",
       "0  el5eh5l  https://www.reddit.com/r/TumblrInAction/commen...      4   \n",
       "1  etotgus  https://www.reddit.com/r/TumblrInAction/commen...     36   \n",
       "2  ep0yt9p  https://www.reddit.com/r/TumblrInAction/commen...     39   \n",
       "3  etnmw0w  https://www.reddit.com/r/TumblrInAction/commen...     46   \n",
       "4  emzvb9e  https://www.reddit.com/r/CCJ2/comments/bmuhp3/...      2   \n",
       "\n",
       "                                                text         anno_ctx  \\\n",
       "0  Seriously though, what the hell am I supposed ...              NaN   \n",
       "1  I agree. Like, I just deal with it because I d...              NaN   \n",
       "2                                        Udon 4 life              NaN   \n",
       "3                   Feminist, Feminism, *Funny, LOL*  PreviousContent   \n",
       "4  Also can't take a shit in a public bathroom wi...              NaN   \n",
       "\n",
       "    anno_tgt           anno_tgt_cat                     label    y  \\\n",
       "0        NaN                    NaN                   Neutral  0.0   \n",
       "1        NaN                    NaN                   Neutral  0.0   \n",
       "2        NaN                    NaN                   Neutral  0.0   \n",
       "3  feminists  political affiliation  AffiliationDirectedAbuse  1.0   \n",
       "4        NaN                    NaN                   Neutral  0.0   \n",
       "\n",
       "   pred_label                                       y_pred  \\\n",
       "0           1   [-0.4662129580974579, 0.13268911838531494]   \n",
       "1           1  [-0.24242620170116425, 0.11224387586116791]   \n",
       "2           0     [1.141236662864685, -0.6677318215370178]   \n",
       "3           1    [-1.1837022304534912, 0.9363416433334351]   \n",
       "4           1    [-1.0287977457046509, 0.5232383608818054]   \n",
       "\n",
       "                                                   x  masked_index  tp  tn  \\\n",
       "0  {'id': 'el5eh5l', 'name': 't1_el5eh5l', 'autho...             4   0   0   \n",
       "1  {'id': 'etotgus', 'name': 't1_etotgus', 'autho...            36   0   0   \n",
       "2  {'id': 'ep0yt9p', 'name': 't1_ep0yt9p', 'autho...            39   0   1   \n",
       "3  {'id': 'etnmw0w', 'name': 't1_etnmw0w', 'autho...            46   1   0   \n",
       "4  {'id': 'emzvb9e', 'name': 't1_emzvb9e', 'autho...             2   0   0   \n",
       "\n",
       "   fp  fn  \n",
       "0   1   0  \n",
       "1   1   0  \n",
       "2   0   0  \n",
       "3   0   0  \n",
       "4   1   0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hatedisc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
