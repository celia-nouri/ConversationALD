{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis for Context-Aware ALD Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contrains the error and qualitative analysis for different models trained on CAD for Abusive Language Detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "import seaborn as sns\n",
    "import os \n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read output test file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../../modernbert-class_cad_eval_test_outputs.jsonl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the jsonl file and read it line by line\n",
    "def get_error_stats(file_path):\n",
    "    true_predictions, tp, tn, false_predictions, fp, fn = 0, 0, 0, 0, 0, 0\n",
    "    model_pred_1, model_pred_0 = 0, 0\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            # Parse the JSON object from each line\n",
    "            json_obj = json.loads(line.strip())\n",
    "            if int(json_obj['pred_label']) == int(json_obj['y']):\n",
    "                true_predictions += 1\n",
    "                if int(json_obj['pred_label']) == 1:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "            else:\n",
    "                false_predictions += 1\n",
    "                if int(json_obj['pred_label']) == 1:\n",
    "                    fp += 1\n",
    "                else:\n",
    "                    fn += 1\n",
    "            \n",
    "            if int(json_obj['pred_label']) == 1:\n",
    "                model_pred_1 += 1\n",
    "            else:\n",
    "                model_pred_0 += 1\n",
    "\n",
    "    return {\n",
    "        \"true_predictions\": true_predictions,\n",
    "        \"true_positives\": tp,\n",
    "        \"true_negatives\": tn,\n",
    "        \"false_predictions\": false_predictions,\n",
    "        \"false_positives\": fp,\n",
    "        \"false_negatives\": fn,\n",
    "        \"model_pred_1\": model_pred_1,\n",
    "        \"model_pred_0\": model_pred_0\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  bert-class\n",
      "Model:  modernbert-class\n",
      "Model:  bert-concat\n",
      "Model:  bertwithneighconcat\n",
      "Model:  gat-test\n",
      "Stats written to model_error_stats.csv\n"
     ]
    }
   ],
   "source": [
    "models = [\"bert-class\", \"modernbert-class\", \"bert-concat\", \"bertwithneighconcat\", \"gat-test\"]\n",
    "stats_list = []\n",
    "\n",
    "for model in models:\n",
    "    file_path = os.path.join(\"../..\", model + \"_cad_eval_test_outputs.jsonl\")\n",
    "    print(\"Model: \", model)\n",
    "    stats = get_error_stats(file_path)\n",
    "    stats[\"model\"] = model  # Add model name to the stats\n",
    "    stats_list.append(stats)\n",
    "\n",
    "# Write stats to a CSV file\n",
    "output_file = \"model_error_stats.csv\"\n",
    "with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=[\n",
    "        \"model\", \"true_predictions\", \"true_positives\", \"true_negatives\",\n",
    "        \"false_predictions\", \"false_positives\", \"false_negatives\",\n",
    "        \"model_pred_1\", \"model_pred_0\"\n",
    "    ])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(stats_list)\n",
    "\n",
    "print(f\"Stats written to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the correspondance between comment/post ids and graph files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/celianouri/anaconda3/envs/hatedisc/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# output content of 100 first graph objetcs into the sample-reanno folder in data folder\n",
    "graph_input_dir = \"../../data/processed_graphs/processed/\"\n",
    "index_file = \"../../data/cad-test-idx-many.txt\"\n",
    "output_file = \"eval_set_output.csv\"\n",
    "output_dic = {}\n",
    "\n",
    "def extract_info_from_graph(index_file, output_file):\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "        fieldnames = ['filename', 'id', 'reddit_url', 'label', 'anno_ctx', 'anno_tgt', 'anno_tgt_cat', 'body', 'index_in_conv', 'conv_len']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        with open(index_file, \"r\") as file:\n",
    "            indices = file.readlines()\n",
    "            indices = [int(index.strip()) for index in indices]\n",
    "            for index in indices:\n",
    "                input_file = f\"{graph_input_dir}graph-{index}.pt\"\n",
    "                try:\n",
    "                    # Load the.pt file\n",
    "                    graph = torch.load(input_file)\n",
    "                    true_index = [i for i in range(len(graph.y_mask)) if graph.y_mask[i] == True]\n",
    "                    assert len(true_index) == 1\n",
    "                    true_index = true_index[0]\n",
    "\n",
    "                    comment = graph.x_text[true_index]\n",
    "                    x, a2, a3, label = comment\n",
    "                    my_id = x.get('id', '')\n",
    "                    permalink = x.get('permalink', '')\n",
    "                    reddit_url = 'https://www.reddit.com' + permalink\n",
    "                    \n",
    "                    label = x.get('label', '')\n",
    "                    anno_ctx = x.get('anno_ctx', '')\n",
    "                    anno_tgt = x.get('anno_tgt', '')\n",
    "                    anno_tgt_cat = x.get('anno_tgt_cat', '')\n",
    "                    body = x.get('body', '')\n",
    "                    \n",
    "                    # Write to CSV\n",
    "                    writer.writerow({\n",
    "                        'filename': input_file,\n",
    "                        'id': my_id,\n",
    "                        'reddit_url': reddit_url,\n",
    "                        'label': label,\n",
    "                        'anno_ctx': anno_ctx,\n",
    "                        'anno_tgt': anno_tgt,\n",
    "                        'anno_tgt_cat': anno_tgt_cat,\n",
    "                        'body': body,\n",
    "                        'index_in_conv': true_index,\n",
    "                        'conv_len': len(graph.y_mask)\n",
    "                    })\n",
    "\n",
    "                    #target_comment = graph.x_text[true_index]\n",
    "                    #print(target_comment)\n",
    "\n",
    "\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"File {input_file} not found.\")\n",
    "\n",
    "\n",
    "extract_info_from_graph(index_file, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check model errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bot-gat-dir-3l-cad-512-7_3625338_eval_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/celianouri/Stage24/HatefulDiscussionsModeling/model_hateful_comments/notebooks'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete! Data saved to /Users/celianouri/Stage24/HatefulDiscussionsModeling/model_hateful_comments/bot-gat-dir-3l-cad-512-42(best)_eval_outputs.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# Input JSONL file\n",
    "input_file = \"/Users/celianouri/Stage24/HatefulDiscussionsModeling/model_hateful_comments/bot-gat-dir-3l-cad-512-42(best)_eval_outputs.jsonl\"\n",
    "# Output CSV file\n",
    "output_file = \"/Users/celianouri/Stage24/HatefulDiscussionsModeling/model_hateful_comments/bot-gat-dir-3l-cad-512-42(best)_eval_outputs.csv\"\n",
    "\n",
    "# Read the JSONL file and extract the data\n",
    "data = []\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line.strip())\n",
    "        obj['tp'], obj['tn'], obj['fp'], obj['fn'] = 0, 0, 0, 0\n",
    "        if int(obj['pred_label']) == int(obj['y']):\n",
    "            if int(obj['pred_label']) == 1:\n",
    "                obj['tp'] = 1\n",
    "            else:\n",
    "                obj['tn'] = 1\n",
    "        else:\n",
    "            if int(obj['pred_label']) == 1:\n",
    "                obj['fp'] = 1\n",
    "            else:\n",
    "                obj['fn'] = 1\n",
    "        data.append(obj)\n",
    "\n",
    "# Flatten and normalize arrays or complex fields into strings\n",
    "def flatten_value(value):\n",
    "    if isinstance(value, list):\n",
    "        return \";\".join(map(str, value))  # Join list elements with semicolons\n",
    "    return value\n",
    "\n",
    "# Get all unique keys in the JSON objects (assuming consistent fields)\n",
    "if data:\n",
    "    headers = data[0].keys()\n",
    "else:\n",
    "    raise ValueError(\"The JSONL file is empty or malformed.\")\n",
    "\n",
    "# Write to CSV\n",
    "with open(output_file, 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    for item in data:\n",
    "        flattened_item = {key: flatten_value(value) for key, value in item.items()}\n",
    "        writer.writerow(flattened_item)\n",
    "\n",
    "print(f\"Conversion complete! Data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "bert_results = pd.read_csv(\"../bertclass-cad-512-123_3625347_eval_outputs.csv\")\n",
    "gat3l_results = pd.read_csv(\"../bot-gat-dir-3l-cad-512-7_3625338_eval_outputs.csv\")\n",
    "gat2l_results = pd.read_csv(\"../bot-gat-dir-2l-cad-512-7_3624560_eval_outputs.csv\")\n",
    "best_bert_results = pd.read_csv(\"../bertclass-cad-512-42(best)_eval_outputs.csv\")\n",
    "best_graph_results = pd.read_csv(\"../bot-gat-dir-3l-cad-512-42(best)_eval_outputs.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does this model perform on context specific samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_bert_results_ctx = best_bert_results[best_bert_results['anno_ctx'] == 'PreviousContent']\n",
    "best_graph_results_ctx = best_graph_results[best_graph_results['anno_ctx'] == 'PreviousContent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reddit_url</th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>anno_ctx</th>\n",
       "      <th>anno_tgt</th>\n",
       "      <th>anno_tgt_cat</th>\n",
       "      <th>label</th>\n",
       "      <th>y</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>texts</th>\n",
       "      <th>conv_indices_to_keep</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>etnmw0w</td>\n",
       "      <td>https://www.reddit.com/r/TumblrInAction/commen...</td>\n",
       "      <td>46</td>\n",
       "      <td>Feminist, Feminism, *Funny, LOL*</td>\n",
       "      <td>PreviousContent</td>\n",
       "      <td>feminists</td>\n",
       "      <td>political affiliation</td>\n",
       "      <td>AffiliationDirectedAbuse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-1.8421907424926758, 1.8497545719146729]</td>\n",
       "      <td>;Normalise masturbation? What does this ever m...</td>\n",
       "      <td>0;1;2;9;12;13;23;24;37;38;46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>eteyggm</td>\n",
       "      <td>https://www.reddit.com/r/Drama/comments/cbchrd...</td>\n",
       "      <td>74</td>\n",
       "      <td>Gypsies of peace strike again.</td>\n",
       "      <td>PreviousContent</td>\n",
       "      <td>romani people</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>IdentityDirectedAbuse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-2.5046000480651855, 2.482245445251465]</td>\n",
       "      <td>;Trumps concentration camps are open for busin...</td>\n",
       "      <td>0;3;32;45;46;60;61;67;68;74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>eio7kct</td>\n",
       "      <td>https://www.reddit.com/r/4chan/comments/b1ta8a...</td>\n",
       "      <td>7</td>\n",
       "      <td>The first guy was trying to run away, can clea...</td>\n",
       "      <td>PreviousContent</td>\n",
       "      <td>brenton tarrant</td>\n",
       "      <td>hateful entities</td>\n",
       "      <td>IdentityDirectedAbuse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-1.2868059873580933, 1.2466493844985962]</td>\n",
       "      <td>;&gt;Shoots man bravely attempting to disarm him\\...</td>\n",
       "      <td>0;3;7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>efxvf7g</td>\n",
       "      <td>https://www.reddit.com/r/4chan/comments/anszg4...</td>\n",
       "      <td>136</td>\n",
       "      <td>I don't need a fucking weebs opinion</td>\n",
       "      <td>PreviousContent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PersonDirectedAbuse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-3.4599242210388184, 3.4274837970733643]</td>\n",
       "      <td>;Brazil? Gonna need an explanation for that on...</td>\n",
       "      <td>0;1;2;67;72;78;80;131;135;136;139;140;142;143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>eofd2ju</td>\n",
       "      <td>https://www.reddit.com/r/conspiracy/comments/b...</td>\n",
       "      <td>2</td>\n",
       "      <td>Our responsibilities lol. The arrogance and en...</td>\n",
       "      <td>PreviousContent</td>\n",
       "      <td>people from america</td>\n",
       "      <td>nationality/origin</td>\n",
       "      <td>IdentityDirectedAbuse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-2.6680080890655518, 2.721731185913086]</td>\n",
       "      <td>;###[Meta] Sticky Comment\\n\\n[Rule 2](https://...</td>\n",
       "      <td>0;1;2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                         reddit_url  index  \\\n",
       "3   etnmw0w  https://www.reddit.com/r/TumblrInAction/commen...     46   \n",
       "17  eteyggm  https://www.reddit.com/r/Drama/comments/cbchrd...     74   \n",
       "18  eio7kct  https://www.reddit.com/r/4chan/comments/b1ta8a...      7   \n",
       "23  efxvf7g  https://www.reddit.com/r/4chan/comments/anszg4...    136   \n",
       "26  eofd2ju  https://www.reddit.com/r/conspiracy/comments/b...      2   \n",
       "\n",
       "                                                 text         anno_ctx  \\\n",
       "3                    Feminist, Feminism, *Funny, LOL*  PreviousContent   \n",
       "17                     Gypsies of peace strike again.  PreviousContent   \n",
       "18  The first guy was trying to run away, can clea...  PreviousContent   \n",
       "23               I don't need a fucking weebs opinion  PreviousContent   \n",
       "26  Our responsibilities lol. The arrogance and en...  PreviousContent   \n",
       "\n",
       "               anno_tgt           anno_tgt_cat                     label    y  \\\n",
       "3             feminists  political affiliation  AffiliationDirectedAbuse  1.0   \n",
       "17        romani people              ethnicity     IdentityDirectedAbuse  1.0   \n",
       "18      brenton tarrant       hateful entities     IdentityDirectedAbuse  1.0   \n",
       "23                  NaN                    NaN       PersonDirectedAbuse  1.0   \n",
       "26  people from america     nationality/origin     IdentityDirectedAbuse  1.0   \n",
       "\n",
       "    pred_label                                     y_pred  \\\n",
       "3            1  [-1.8421907424926758, 1.8497545719146729]   \n",
       "17           1   [-2.5046000480651855, 2.482245445251465]   \n",
       "18           1  [-1.2868059873580933, 1.2466493844985962]   \n",
       "23           1  [-3.4599242210388184, 3.4274837970733643]   \n",
       "26           1   [-2.6680080890655518, 2.721731185913086]   \n",
       "\n",
       "                                                texts  \\\n",
       "3   ;Normalise masturbation? What does this ever m...   \n",
       "17  ;Trumps concentration camps are open for busin...   \n",
       "18  ;>Shoots man bravely attempting to disarm him\\...   \n",
       "23  ;Brazil? Gonna need an explanation for that on...   \n",
       "26  ;###[Meta] Sticky Comment\\n\\n[Rule 2](https://...   \n",
       "\n",
       "                             conv_indices_to_keep  tp  tn  fp  fn  \n",
       "3                    0;1;2;9;12;13;23;24;37;38;46   1   0   0   0  \n",
       "17                    0;3;32;45;46;60;61;67;68;74   1   0   0   0  \n",
       "18                                          0;3;7   1   0   0   0  \n",
       "23  0;1;2;67;72;78;80;131;135;136;139;140;142;143   1   0   0   0  \n",
       "26                                          0;1;2   1   0   0   0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_graph_results_ctx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reddit_url</th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>anno_ctx</th>\n",
       "      <th>anno_tgt</th>\n",
       "      <th>anno_tgt_cat</th>\n",
       "      <th>label</th>\n",
       "      <th>y</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>x</th>\n",
       "      <th>masked_index</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>etnmw0w</td>\n",
       "      <td>https://www.reddit.com/r/TumblrInAction/commen...</td>\n",
       "      <td>46</td>\n",
       "      <td>Feminist, Feminism, *Funny, LOL*</td>\n",
       "      <td>PreviousContent</td>\n",
       "      <td>feminists</td>\n",
       "      <td>political affiliation</td>\n",
       "      <td>AffiliationDirectedAbuse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-1.1428617238998413, 1.2060739994049072]</td>\n",
       "      <td>{'id': 'etnmw0w', 'name': 't1_etnmw0w', 'autho...</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>eteyggm</td>\n",
       "      <td>https://www.reddit.com/r/Drama/comments/cbchrd...</td>\n",
       "      <td>74</td>\n",
       "      <td>Gypsies of peace strike again.</td>\n",
       "      <td>PreviousContent</td>\n",
       "      <td>romani people</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>IdentityDirectedAbuse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-1.4758193492889404, 1.5208029747009277]</td>\n",
       "      <td>{'id': 'eteyggm', 'name': 't1_eteyggm', 'autho...</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>eio7kct</td>\n",
       "      <td>https://www.reddit.com/r/4chan/comments/b1ta8a...</td>\n",
       "      <td>7</td>\n",
       "      <td>The first guy was trying to run away, can clea...</td>\n",
       "      <td>PreviousContent</td>\n",
       "      <td>brenton tarrant</td>\n",
       "      <td>hateful entities</td>\n",
       "      <td>IdentityDirectedAbuse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.03366149216890335, 0.3167352080345154]</td>\n",
       "      <td>{'id': 'eio7kct', 'name': 't1_eio7kct', 'autho...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>efxvf7g</td>\n",
       "      <td>https://www.reddit.com/r/4chan/comments/anszg4...</td>\n",
       "      <td>136</td>\n",
       "      <td>I don't need a fucking weebs opinion</td>\n",
       "      <td>PreviousContent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PersonDirectedAbuse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-1.526110291481018, 1.7947399616241455]</td>\n",
       "      <td>{'id': 'efxvf7g', 'name': 't1_efxvf7g', 'autho...</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>eofd2ju</td>\n",
       "      <td>https://www.reddit.com/r/conspiracy/comments/b...</td>\n",
       "      <td>2</td>\n",
       "      <td>Our responsibilities lol. The arrogance and en...</td>\n",
       "      <td>PreviousContent</td>\n",
       "      <td>people from america</td>\n",
       "      <td>nationality/origin</td>\n",
       "      <td>IdentityDirectedAbuse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-1.7145277261734009, 1.851286768913269]</td>\n",
       "      <td>{'id': 'eofd2ju', 'name': 't1_eofd2ju', 'autho...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                         reddit_url  index  \\\n",
       "3   etnmw0w  https://www.reddit.com/r/TumblrInAction/commen...     46   \n",
       "17  eteyggm  https://www.reddit.com/r/Drama/comments/cbchrd...     74   \n",
       "18  eio7kct  https://www.reddit.com/r/4chan/comments/b1ta8a...      7   \n",
       "23  efxvf7g  https://www.reddit.com/r/4chan/comments/anszg4...    136   \n",
       "26  eofd2ju  https://www.reddit.com/r/conspiracy/comments/b...      2   \n",
       "\n",
       "                                                 text         anno_ctx  \\\n",
       "3                    Feminist, Feminism, *Funny, LOL*  PreviousContent   \n",
       "17                     Gypsies of peace strike again.  PreviousContent   \n",
       "18  The first guy was trying to run away, can clea...  PreviousContent   \n",
       "23               I don't need a fucking weebs opinion  PreviousContent   \n",
       "26  Our responsibilities lol. The arrogance and en...  PreviousContent   \n",
       "\n",
       "               anno_tgt           anno_tgt_cat                     label    y  \\\n",
       "3             feminists  political affiliation  AffiliationDirectedAbuse  1.0   \n",
       "17        romani people              ethnicity     IdentityDirectedAbuse  1.0   \n",
       "18      brenton tarrant       hateful entities     IdentityDirectedAbuse  1.0   \n",
       "23                  NaN                    NaN       PersonDirectedAbuse  1.0   \n",
       "26  people from america     nationality/origin     IdentityDirectedAbuse  1.0   \n",
       "\n",
       "    pred_label                                      y_pred  \\\n",
       "3            1   [-1.1428617238998413, 1.2060739994049072]   \n",
       "17           1   [-1.4758193492889404, 1.5208029747009277]   \n",
       "18           1  [-0.03366149216890335, 0.3167352080345154]   \n",
       "23           1    [-1.526110291481018, 1.7947399616241455]   \n",
       "26           1    [-1.7145277261734009, 1.851286768913269]   \n",
       "\n",
       "                                                    x  masked_index  tp  tn  \\\n",
       "3   {'id': 'etnmw0w', 'name': 't1_etnmw0w', 'autho...            46   1   0   \n",
       "17  {'id': 'eteyggm', 'name': 't1_eteyggm', 'autho...            74   1   0   \n",
       "18  {'id': 'eio7kct', 'name': 't1_eio7kct', 'autho...             7   1   0   \n",
       "23  {'id': 'efxvf7g', 'name': 't1_efxvf7g', 'autho...           136   1   0   \n",
       "26  {'id': 'eofd2ju', 'name': 't1_eofd2ju', 'autho...             2   1   0   \n",
       "\n",
       "    fp  fn  \n",
       "3    0   0  \n",
       "17   0   0  \n",
       "18   0   0  \n",
       "23   0   0  \n",
       "26   0   0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_bert_results_ctx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model with best performance on context 'PreviousContent':\n",
      "tp    80\n",
      "tn     2\n",
      "fp     1\n",
      "fn    30\n",
      "dtype: int64\n",
      "BERT model with best performance on context 'CurrentContext':\n",
      "tp    201\n",
      "tn      0\n",
      "fp      2\n",
      "fn     37\n",
      "dtype: int64\n",
      "Best BERT model is wrong on 27.272727272727273 % of Previous Context cases.\n",
      "Best BERT model is wrong on 15.546218487394958 % of Current Context cases.\n"
     ]
    }
   ],
   "source": [
    "summary_ctx = best_bert_results_ctx[['tp', 'tn', 'fp', 'fn']].sum()\n",
    "print(\"BERT model with best performance on context 'PreviousContent':\")\n",
    "print(summary_ctx)\n",
    "\n",
    "best_bert_results_currctx = best_bert_results[best_bert_results['anno_ctx'] == 'CurrentContent']\n",
    "summary_currctx = best_bert_results_currctx[['tp', 'tn', 'fp', 'fn']].sum()\n",
    "print(\"BERT model with best performance on context 'CurrentContext':\")\n",
    "print(summary_currctx)\n",
    "\n",
    "print(f\"Best BERT model is wrong on {summary_ctx['fn']*100/(summary_ctx['fn'] + summary_ctx['tp'])} % of Previous Context cases.\")\n",
    "print(f\"Best BERT model is wrong on {summary_currctx['fn']*100/(summary_currctx['fn'] + summary_currctx['tp'])} % of Current Context cases.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph model with best performance on context 'PreviousContent':\n",
      "tp    86\n",
      "tn     2\n",
      "fp     1\n",
      "fn    24\n",
      "dtype: int64\n",
      "Graph model with best performance on context 'CurrentContext':\n",
      "tp    206\n",
      "tn      0\n",
      "fp      2\n",
      "fn     32\n",
      "dtype: int64\n",
      "Best Graph model is wrong on 21.818181818181817 % of Previous Context cases.\n",
      "Best Graph model is wrong on 13.445378151260504 % of Current Context cases.\n"
     ]
    }
   ],
   "source": [
    "summary_ctx = best_graph_results_ctx[['tp', 'tn', 'fp', 'fn']].sum()\n",
    "print(\"Graph model with best performance on context 'PreviousContent':\")\n",
    "print(summary_ctx)\n",
    "\n",
    "best_graph_results_currctx = best_graph_results[best_graph_results['anno_ctx'] == 'CurrentContent']\n",
    "summary_currctx = best_graph_results_currctx[['tp', 'tn', 'fp', 'fn']].sum()\n",
    "print(\"Graph model with best performance on context 'CurrentContext':\")\n",
    "print(summary_currctx)\n",
    "\n",
    "print(f\"Best Graph model is wrong on {summary_ctx['fn']*100/(summary_ctx['fn'] + summary_ctx['tp'])} % of Previous Context cases.\")\n",
    "print(f\"Best Graph model is wrong on {summary_currctx['fn']*100/(summary_currctx['fn'] + summary_currctx['tp'])} % of Current Context cases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_errors = bert_results[(bert_results[\"fp\"] == 1) | (bert_results[\"fn\"] == 1)]\n",
    "gat3l_errors = gat3l_results[(gat3l_results[\"fp\"] == 1) | (gat3l_results[\"fn\"] == 1)]\n",
    "gat2l_errors = gat2l_results[(gat2l_results[\"fp\"] == 1) | (gat2l_results[\"fn\"] == 1)]\n",
    "best_bert_errors = best_bert_results[(best_bert_results[\"fp\"] == 1) | (best_bert_results[\"fn\"] == 1)]\n",
    "best_graph_errors = best_graph_results[(best_graph_results[\"fp\"] == 1) | (best_graph_results[\"fn\"] == 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r7/0255tsrx2dscctsn_23l9c300000gn/T/ipykernel_36125/1321849656.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  best_bert_errors[\"model\"] = \"bert no context\"\n",
      "/var/folders/r7/0255tsrx2dscctsn_23l9c300000gn/T/ipykernel_36125/1321849656.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  best_graph_errors[\"model\"] = \"Best graph model (3l)\"\n"
     ]
    }
   ],
   "source": [
    "best_bert_errors[\"model\"] = \"bert no context\"\n",
    "best_graph_errors[\"model\"] = \"Best graph model (3l)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best BERT model errors: false positives and false negatives\n",
      "fp    112\n",
      "fn     68\n",
      "dtype: int64\n",
      "Best Graph model errors: false positives and false negatives\n",
      "fp    114\n",
      "fn     57\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Best BERT model errors: false positives and false negatives\")\n",
    "summary_err = best_bert_errors[['fp', 'fn']].sum()\n",
    "print(summary_err)\n",
    "\n",
    "print(\"Best Graph model errors: false positives and false negatives\")\n",
    "summary_err = best_graph_errors[['fp', 'fn']].sum()\n",
    "print(summary_err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique IDs in GAT 3l errors: 31\n",
      "Number of unique IDs in BERT no context errors: 40\n",
      "Number of unique IDs that are errors for both models: 140\n",
      "Number of errors for GAT 3l: 179\n",
      "Number of errors for BERT no context: 186\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Merge with an indicator column\n",
    "merged_df = best_graph_errors.merge(best_bert_errors, on='id', how='outer', indicator=True)\n",
    "\n",
    "# Compute statistics\n",
    "unique_in_graph = (merged_df['_merge'] == 'left_only').sum()\n",
    "unique_in_bert = (merged_df['_merge'] == 'right_only').sum()\n",
    "unique_in_both = (merged_df['_merge'] == 'both').sum()\n",
    "total_in_graph = gat3l_errors['id'].nunique()\n",
    "total_in_bert = bert_errors['id'].nunique()\n",
    "\n",
    "# Print results\n",
    "print(\"Number of unique IDs in GAT 3l errors:\", unique_in_graph)\n",
    "print(\"Number of unique IDs in BERT no context errors:\", unique_in_bert)\n",
    "print(\"Number of unique IDs that are errors for both models:\", unique_in_both)\n",
    "print(\"Number of errors for GAT 3l:\", total_in_graph)\n",
    "print(\"Number of errors for BERT no context:\", total_in_bert)\n",
    "\n",
    "graph_only_err = merged_df[(merged_df['_merge'] == 'left_only')]\n",
    "bert_only_err = merged_df[(merged_df['_merge'] == 'right_only')]\n",
    "\n",
    "\n",
    "# Save rows_only_in_df1 as a CSV file\n",
    "#unique_in_gat3l.to_csv('errors_for_gat3l_but_not_bert.csv', index=False)\n",
    "\n",
    "# Save rows_only_in_df2 as a CSV file\n",
    "#unique_in_bert.to_csv('errors_for_bert_but_not_gat3l.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors solved by the Graph model over BERT: 40\n"
     ]
    }
   ],
   "source": [
    "# Errors that were solved by the Graph model over BERT\n",
    "solved_by_graph = merged_df[(merged_df['_merge'] == 'right_only')]\n",
    "\n",
    "print(\"Number of errors solved by the Graph model over BERT:\", len(solved_by_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors that remain errors for both models: 140\n"
     ]
    }
   ],
   "source": [
    "# Errors that remain errors for both models\n",
    "errors_in_both = merged_df[(merged_df['_merge'] == 'both')]\n",
    "\n",
    "print(\"Number of errors that remain errors for both models:\", len(errors_in_both))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save rows_only_in_df1 as a CSV file\n",
    "solved_by_graph.to_csv('solved_by_graph(_over_bert_noctxt).csv', index=False)\n",
    "\n",
    "# Save rows_only_in_df2 as a CSV file\n",
    "#unique_in_bert.to_csv('errors_for_bert_but_not_gat3l.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Older code for old bert and old gat 3l models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r7/0255tsrx2dscctsn_23l9c300000gn/T/ipykernel_25148/1910911973.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gat3l_errors[\"model\"] = \"gat 3l\"\n"
     ]
    }
   ],
   "source": [
    "gat3l_errors[\"model\"] = \"gat 3l\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r7/0255tsrx2dscctsn_23l9c300000gn/T/ipykernel_25148/3368721764.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gat2l_errors[\"model\"] = \"gat 2l\"\n"
     ]
    }
   ],
   "source": [
    "gat2l_errors[\"model\"] = \"gat 2l\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique IDs in GAT 3l errors: 38\n",
      "Number of unique IDs in BERT no context errors: 45\n",
      "Number of unique IDs that are errors for both models: 141\n",
      "Number of errors for GAT 3l: 179\n",
      "Number of errors for BERT no context: 186\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Merge with an indicator column\n",
    "merged_df = gat3l_errors.merge(bert_errors, on='id', how='outer', indicator=True)\n",
    "\n",
    "# Compute statistics\n",
    "unique_in_gat3l = (merged_df['_merge'] == 'left_only').sum()\n",
    "unique_in_bert = (merged_df['_merge'] == 'right_only').sum()\n",
    "unique_in_both = (merged_df['_merge'] == 'both').sum()\n",
    "total_in_gat3l = gat3l_errors['id'].nunique()\n",
    "total_in_bert = bert_errors['id'].nunique()\n",
    "\n",
    "# Print results\n",
    "print(\"Number of unique IDs in GAT 3l errors:\", unique_in_gat3l)\n",
    "print(\"Number of unique IDs in BERT no context errors:\", unique_in_bert)\n",
    "print(\"Number of unique IDs that are errors for both models:\", unique_in_both)\n",
    "print(\"Number of errors for GAT 3l:\", total_in_gat3l)\n",
    "print(\"Number of errors for BERT no context:\", total_in_bert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_in_gat3l = merged_df[(merged_df['_merge'] == 'left_only')]\n",
    "unique_in_bert = merged_df[(merged_df['_merge'] == 'right_only')]\n",
    "\n",
    "\n",
    "# Save rows_only_in_df1 as a CSV file\n",
    "unique_in_gat3l.to_csv('errors_for_gat3l_but_not_bert.csv', index=False)\n",
    "\n",
    "# Save rows_only_in_df2 as a CSV file\n",
    "unique_in_bert.to_csv('errors_for_bert_but_not_gat3l.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context boolean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_errors = bert_results[(bert_results[\"fp\"] == 1) | (bert_results[\"fn\"] == 1)]\n",
    "gat3l_errors = gat3l_results[(gat3l_results[\"fp\"] == 1) | (gat3l_results[\"fn\"] == 1)]\n",
    "gat2l_errors = gat2l_results[(gat2l_results[\"fp\"] == 1) | (gat2l_results[\"fn\"] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for BERT:\n",
      "          anno_ctx  fp  fn   tp  tn\n",
      "0   CurrentContent   2  51  187   0\n",
      "1  PreviousContent   1  38   72   2\n",
      "\n",
      "Summary for GAT 3l :\n",
      "          anno_ctx  fp  fn   tp  tn\n",
      "0   CurrentContent   2  34  204   0\n",
      "1  PreviousContent   1  28   82   2\n"
     ]
    }
   ],
   "source": [
    "# Group by context_boolean and sum up the fp, fn, tp, and tn columns\n",
    "summary_bert = bert_results.groupby('anno_ctx')[['fp', 'fn', 'tp', 'tn']].sum().reset_index()\n",
    "summary_gat3l = gat3l_results.groupby('anno_ctx')[['fp', 'fn', 'tp', 'tn']].sum().reset_index()\n",
    "\n",
    "# Display the summary tables\n",
    "print(\"Summary for BERT:\")\n",
    "print(summary_bert)\n",
    "\n",
    "print(\"\\nSummary for GAT 3l :\")\n",
    "print(summary_gat3l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third set of F1 scores\n",
    "f1_scores= {\n",
    "    \"BERT (no context)\" : np.array([0.75806, 0.75497, 0.73654, 0.75632, 0.72859]),\n",
    "    \"BERT concat embeddings (all conv)\": np.array([0.63934, 0.53741, 0.63934, 0.63934, 0.63934]),\n",
    "    \"Longf concat context\":  np.array([0.7668, 0.73727, 0.7358, 0.75098, 0.741]), \n",
    "    \"Gat 1l\": np.array([0.75034, 0.74929, 0.75033, 0.73741, 0.75493]),\n",
    "    \"Gat 2l\": np.array([0.76533, 0.76501, 0.74834, 0.76294, 0.75683]),\n",
    "    \"Gat 3l\": np.array([0.77411, 0.76228, 0.75275, 0.75467, 0.7655]),\n",
    "    \"Gat 4l\": np.array([0.7644, 0.76319, 0.74716, 0.76883, 0.74967]),\n",
    "}\n",
    "\n",
    "model_names, mean_f1_scores, stds, conf_ints, ci_lowers, ci_uppers  = [], [], [], [], [], []\n",
    "\n",
    "n = 5\n",
    "t = 2.70 #2.776 # t value for n=5 and a 95% confidence interval \n",
    "\n",
    "\n",
    "for model, f1s in f1_scores.items():\n",
    "    model_names.append(model)\n",
    "    mean_f1 = np.mean(f1s)\n",
    "    mean_f1_scores.append(mean_f1)\n",
    "\n",
    "    # Compute standard deviation\n",
    "    std_ = np.std(f1s, ddof=1)\n",
    "    stds.append(std_)\n",
    "\n",
    "    # Compute confidence interval\n",
    "    conf = t * (std_ / np.sqrt(n))\n",
    "    conf_ints.append(conf)\n",
    "    ci_lowers.append(mean_f1 - conf)\n",
    "    ci_uppers.append(mean_f1 + conf)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Model Name': model_names,\n",
    "    'Mean F1': mean_f1_scores,\n",
    "    'Standard Deviation': stds,\n",
    "    'Confidence Interval': conf_ints,\n",
    "    'Confidence Interval Lower': ci_lowers,\n",
    "    'Confidence Interval Upper': ci_uppers,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Mean F1</th>\n",
       "      <th>Standard Deviation</th>\n",
       "      <th>Confidence Interval</th>\n",
       "      <th>Confidence Interval Lower</th>\n",
       "      <th>Confidence Interval Upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERT (no context)</td>\n",
       "      <td>0.746896</td>\n",
       "      <td>0.013426</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.734888</td>\n",
       "      <td>0.758904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BERT concat embeddings (all conv)</td>\n",
       "      <td>0.618954</td>\n",
       "      <td>0.045584</td>\n",
       "      <td>0.040772</td>\n",
       "      <td>0.578182</td>\n",
       "      <td>0.659726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Longf concat context</td>\n",
       "      <td>0.746370</td>\n",
       "      <td>0.012865</td>\n",
       "      <td>0.011507</td>\n",
       "      <td>0.734863</td>\n",
       "      <td>0.757877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gat 1l</td>\n",
       "      <td>0.748460</td>\n",
       "      <td>0.006551</td>\n",
       "      <td>0.005860</td>\n",
       "      <td>0.742600</td>\n",
       "      <td>0.754320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gat 2l</td>\n",
       "      <td>0.759690</td>\n",
       "      <td>0.007205</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>0.753245</td>\n",
       "      <td>0.766135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gat 3l</td>\n",
       "      <td>0.761862</td>\n",
       "      <td>0.008634</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>0.754140</td>\n",
       "      <td>0.769584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gat 4l</td>\n",
       "      <td>0.758650</td>\n",
       "      <td>0.009617</td>\n",
       "      <td>0.008602</td>\n",
       "      <td>0.750048</td>\n",
       "      <td>0.767252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model Name   Mean F1  Standard Deviation  \\\n",
       "0                  BERT (no context)  0.746896            0.013426   \n",
       "1  BERT concat embeddings (all conv)  0.618954            0.045584   \n",
       "2               Longf concat context  0.746370            0.012865   \n",
       "3                             Gat 1l  0.748460            0.006551   \n",
       "4                             Gat 2l  0.759690            0.007205   \n",
       "5                             Gat 3l  0.761862            0.008634   \n",
       "6                             Gat 4l  0.758650            0.009617   \n",
       "\n",
       "   Confidence Interval  Confidence Interval Lower  Confidence Interval Upper  \n",
       "0             0.012008                   0.734888                   0.758904  \n",
       "1             0.040772                   0.578182                   0.659726  \n",
       "2             0.011507                   0.734863                   0.757877  \n",
       "3             0.005860                   0.742600                   0.754320  \n",
       "4             0.006445                   0.753245                   0.766135  \n",
       "5             0.007722                   0.754140                   0.769584  \n",
       "6             0.008602                   0.750048                   0.767252  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hatedisc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
